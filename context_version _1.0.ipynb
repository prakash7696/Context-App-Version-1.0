{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f496b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_split': 10}\n",
      "Accuracy: 0.3181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_excel(r'D:\\DA\\Innotrat LABS\\Intent or Context Analysis\\new_generated_context.xlsx')\n",
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Convert text data into TF-IDF features\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "#param_grid = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,10))}]\n",
    "param_grid = {\n",
    "    'max_depth': [None,1,3,5],\n",
    "    'min_samples_split': [2,5,10]\n",
    "}\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv = 10, scoring='accuracy')\n",
    "\n",
    "# Train the classifier with grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = grid_search.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Print the best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6fdde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How to fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text = 'How do you handle quality issues or non-conforming PCBs during the manufacturing process? Can you share your corrective action and preventive action (CAPA) processes for maintaining high-quality standards?'\n",
    "\n",
    "test_X = vectorizer.transform([new_text])\n",
    "predictions = grid_search.predict(test_X)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c91f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_2 = 'I am interested in manufacturing PCBs for my project. Attached are the gerber and design files. Kindly provide a quotation for approximately 100 units. Also, please let me know the estimated manufacturing timeline'\n",
    "\n",
    "test_X_2 = vectorizer.transform([new_text_2])\n",
    "predictions = grid_search.predict(test_X_2)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a129220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_3 = 'Request for PCB Manufacturing - Urgent Project'\n",
    "\n",
    "test_X_3 = vectorizer.transform([new_text_3])\n",
    "predictions = grid_search.predict(test_X_3)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f32960c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Can you fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_4 = 'Hi Team, I need a PCB project which I need urgent delivery. I am sharing my details kindly let me know the next process'\n",
    "\n",
    "test_X_4 = vectorizer.transform([new_text_4])\n",
    "predictions = grid_search.predict(test_X_4)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a8129",
   "metadata": {},
   "source": [
    "# Final Model Version 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a7e913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_split': 10}\n",
      "Accuracy: 0.4318181818181818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df = pd.read_excel(r'D:\\DA\\Innotrat LABS\\Intent or Context Analysis\\new_generated_context.xlsx')\n",
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "texts = texts.str.lower()\n",
    "labels = labels.str.lower()\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Convert text data into TF-IDF features\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "#param_grid = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,10))}]\n",
    "param_grid = {\n",
    "    'max_depth': [None,1,3,5],\n",
    "    'min_samples_split': [2,5,10]\n",
    "}\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv = 10, scoring='accuracy')\n",
    "\n",
    "# Train the classifier with grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = grid_search.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Print the best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5545fe98",
   "metadata": {},
   "source": [
    "# Model and Vectorizer Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "216c9104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(grid_search.best_estimator_, 'decision_tree_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d510e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer_context.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer, 'vectorizer_context.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fcd058",
   "metadata": {},
   "source": [
    "# Model and Vectorizer loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abd8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#load the model\n",
    "model = joblib.load('decision_tree_model.pkl')\n",
    "#load vectorizer\n",
    "vectorizer = joblib.load('vectorizer_context.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a15846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how to fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text = 'How do you handle quality issues or non-conforming PCBs during the manufacturing process? Can you share your corrective action and preventive action (CAPA) processes for maintaining high-quality standards?'\n",
    "\n",
    "test_X = vectorizer.transform([new_text])\n",
    "predictions = grid_search.predict(test_X)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f25bffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i need this design to fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_2 = 'I am interested in manufacturing PCBs for my project. Attached are the gerber and design files. Kindly provide a quotation for approximately 100 units. Also, please let me know the estimated manufacturing timeline'\n",
    "\n",
    "test_X_2 = vectorizer.transform([new_text_2])\n",
    "predictions = grid_search.predict(test_X_2)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "281a0fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_3 = 'Request for PCB Manufacturing - Urgent Project'\n",
    "\n",
    "test_X_3 = vectorizer.transform([new_text_3])\n",
    "predictions = grid_search.predict(test_X_3)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4c1c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_4 = 'Hi Team, I need a PCB project which I need urgent delivery. I am sharing my details kindly let me know the next process'\n",
    "\n",
    "test_X_4 = vectorizer.transform([new_text_4])\n",
    "predictions = grid_search.predict(test_X_4)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e1e143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_5 = 'Hi Team, My order number is 1234. I want to know the status of my order'\n",
    "test_X_5 = vectorizer.transform([new_text_5])\n",
    "predictions = grid_search.predict(test_X_5)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02385a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36363636363636365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer #CountVectorizer \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_excel(r'D:\\DA\\Innotrat LABS\\Intent or Context Analysis\\new_generated_context.xlsx')\n",
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Convert text data into TF-IDF features\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fe4ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How to fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text = 'How do you handle quality issues or non-conforming PCBs during the manufacturing process? Can you share your corrective action and preventive action (CAPA) processes for maintaining high-quality standards?'\n",
    "\n",
    "test_X = vectorizer.transform([new_text])\n",
    "predictions = svm_classifier.predict(test_X)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b431e5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_2 = 'I am interested in manufacturing PCBs for my project. Attached are the gerber and design files. Kindly provide a quotation for approximately 100 units. Also, please let me know the estimated manufacturing timeline'\n",
    "\n",
    "test_X_2 = vectorizer.transform([new_text_2])\n",
    "predictions = svm_classifier.predict(test_X_2)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad283715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_3 = 'Request for PCB Manufacturing - Urgent Project'\n",
    "\n",
    "test_X_3 = vectorizer.transform([new_text_3])\n",
    "predictions = svm_classifier.predict(test_X_3)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e58f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_4 = 'Hi Team, I need a PCB project which I need urgent delivery. I am sharing my details kindly let me know the next process'\n",
    "\n",
    "test_X_4 = vectorizer.transform([new_text_4])\n",
    "predictions = svm_classifier.predict(test_X_4)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e374276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_5 = 'Hi Team, My order number is 1234. I want to know the status of my order'\n",
    "test_X_5 = vectorizer.transform([new_text_5])\n",
    "predictions = svm_classifier.predict(test_X_5)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1de4409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.4090909090909091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer #CountVectorizer \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_excel(r'D:\\DA\\Innotrat LABS\\Intent or Context Analysis\\new_generated_context.xlsx')\n",
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "classifier = SVC()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv = 5, scoring='accuracy')\n",
    "\n",
    "# Train the classifier with grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = grid_search.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Print the best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddba149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How to fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text = 'How do you handle quality issues or non-conforming PCBs during the manufacturing process? Can you share your corrective action and preventive action (CAPA) processes for maintaining high-quality standards?'\n",
    "\n",
    "test_X = vectorizer.transform([new_text])\n",
    "predictions = grid_search.predict(test_X)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90cee9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_2 = 'I am interested in manufacturing PCBs for my project. Attached are the gerber and design files. Kindly provide a quotation for approximately 100 units. Also, please let me know the estimated manufacturing timeline'\n",
    "\n",
    "test_X_2 = vectorizer.transform([new_text_2])\n",
    "predictions = grid_search.predict(test_X_2)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2220cd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_3 = 'Request for PCB Manufacturing - Urgent Project'\n",
    "\n",
    "test_X_3 = vectorizer.transform([new_text_3])\n",
    "predictions = grid_search.predict(test_X_3)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb5686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_4 = 'Hi Team, I need a PCB project which I need urgent delivery. I am sharing my details kindly let me know the next process'\n",
    "\n",
    "test_X_4 = vectorizer.transform([new_text_4])\n",
    "predictions = grid_search.predict(test_X_4)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1de0ecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_5 = 'Hi Team, My order number is 1234. I want to know the status of my order'\n",
    "test_X_5 = vectorizer.transform([new_text_5])\n",
    "predictions = grid_search.predict(test_X_5)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb477ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy: 0.3181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import  CountVectorizer #TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_excel(r'D:\\DA\\Innotrat LABS\\Intent or Context Analysis\\new_generated_context.xlsx')\n",
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "classifier = SVC()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv = 5, scoring='accuracy')\n",
    "\n",
    "# Train the classifier with grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = grid_search.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Print the best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13dd224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear', 'vectorizer__ngram_range': (1, 1)}\n",
      "Accuracy: 0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(r'D:\\DA\\Innotrat LABS\\Intent or Context Analysis\\new_generated_context.xlsx')\n",
    "texts = df['text']\n",
    "labels = df['label']\n",
    "\n",
    "texts = texts.str.lower()\n",
    "labels = labels.str.lower()\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the tokenizer function\n",
    "def tokenizer(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=tokenizer)),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__kernel': ['linear', 'rbf'],\n",
    "    'classifier__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Train the classifier with grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = grid_search.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Print the best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4597c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: ['how to fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text = 'How do you handle quality issues or non-conforming PCBs during the manufacturing process? Can you share your corrective action and preventive action (CAPA) processes for maintaining high-quality standards?'\n",
    "best_model = grid_search.best_estimator_\n",
    "predicted_label = best_model.predict([new_text])\n",
    "print(\"Predicted Label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fa9ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: ['who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_2 = 'I am interested in manufacturing PCBs for my project. Attached are the gerber and design files. Kindly provide a quotation for approximately 100 units. Also, please let me know the estimated manufacturing timeline'\n",
    "best_model = grid_search.best_estimator_\n",
    "predicted_label = best_model.predict([new_text_2])\n",
    "print(\"Predicted Label:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f03b2271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: ['Who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_3 = 'Request for PCB Manufacturing - Urgent Project'\n",
    "best_model = grid_search.best_estimator_\n",
    "predicted_label = best_model.predict([new_text_3])\n",
    "print(\"Predicted Label:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1691e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: ['Who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_4 = 'Hi Team, I need a PCB project which I need urgent delivery. I am sharing my details kindly let me know the next process'\n",
    "best_model = grid_search.best_estimator_\n",
    "predicted_label = best_model.predict([new_text_4])\n",
    "print(\"Predicted Label:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0863b4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: ['Who can help me fabricate']\n"
     ]
    }
   ],
   "source": [
    "new_text_5 = 'Hi Team, My order number is 1234. I want to know the status of my order'\n",
    "best_model = grid_search.best_estimator_\n",
    "predicted_label = best_model.predict([new_text_5])\n",
    "print(\"Predicted Label:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0dbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
